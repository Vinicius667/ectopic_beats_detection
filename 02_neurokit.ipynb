{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39720,"status":"ok","timestamp":1701127818008,"user":{"displayName":"VinÃ­cius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"szNbhQ4E7aGA","outputId":"db7b37b0-366a-491b-f7d6-8231b968d3c4"},"outputs":[],"source":["import sys\n","# Delete all global variables when re-running the notebook.\n","this = sys.modules[__name__] # type: ignore\n","for n in dir():\n","    if n in ['this', 'was_mounted']: continue\n","    if n[0]!='_': delattr(this, n)\n","\n","\n","try:\n","    was_mounted = was_mounted\n","except:\n","    was_mounted = False\n","\n","\n","import os\n","if  os.getenv(\"COLAB_RELEASE_TAG\"):\n","  is_running_on_colab = True\n","\n","else:\n","  is_running_on_colab = False\n","\n","if is_running_on_colab:\n","  packages_to_install = ['pandas==2.1.3','neurokit2', 'wfdb']\n","\n","  for package in packages_to_install:\n","    os.system(f'pip install {package}')\n","  from google.colab import drive, files\n","  code_directory = './gdrive/MyDrive/TCC/ectopic_beats_detection'\n","  if not was_mounted:\n","      drive.mount('/content/gdrive')\n","  was_mounted = True\n","  if not os.path.samefile(os.getcwd(),code_directory):\n","    os.chdir(code_directory)\n","\n","from utils import create_compare_df, create_dict_results, plot_results, calculate_metrics, resolve_relative_path\n","from globals import *\n","import sys\n","import neurokit2 as nk\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import numpy as np\n","import pyarrow as pa\n","from os.path import join\n","import pyarrow as pa\n","from typing import Any, Dict, Iterable, List, Tuple, Union\n","from numpy import typing as npt\n","from utils import Processor, Processors, load_df_multi_analysis, load_record, apply_processors, correct_peaks\n","from datetime import datetime\n","import pickle\n","from multiprocessing import Pool, cpu_count\n","from timeit import default_timer as timer\n","import glob\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 40)\n","\n","df_record_lead_ann = pd.read_parquet(join(dataframes_directory, 'df_record_lead_ann.parquet'))\n","df_lead_ann_summery =  pd.read_parquet(join(dataframes_directory, 'df_lead_ann_summery.parquet'))\n","df_ann_summery = pd.read_parquet(join(dataframes_directory, 'df_ann_summery.parquet'))\n","df_code_description = pd.read_parquet(join(dataframes_directory, 'df_code_description.parquet'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_multi_analysis = load_df_multi_analysis(glob.glob(join(dataframes_directory, 'dict_multi_analysis*.pickle')))\n","df_multi_analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_multi_analysis[df_multi_analysis.duplicated()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_multi_analysis.groupby(['record_num']).record_num.count().head(40)"]},{"cell_type":"markdown","metadata":{"id":"OgKgTe3dpg4N"},"source":["# Multiple record analysis"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJhJzM_upg4P","outputId":"8bb6ec45-d102-438b-9cf6-92631d138353"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 84.4640012000018 seconds\n","Processing record 105\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 87.14081029999943 seconds\n","Processing record 106\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 93.16121740000017 seconds\n","Processing record 107\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 93.00020089999816 seconds\n","Processing record 108\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 94.77426350000314 seconds\n","Processing record 109\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 92.83948349999991 seconds\n","Processing record 111\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 94.59155610000016 seconds\n","Processing record 112\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 95.31315050000194 seconds\n","Processing record 113\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 90.81903380000222 seconds\n","Processing record 114\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 88.10766159999912 seconds\n","Processing record 115\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 93.10374089999823 seconds\n","Processing record 116\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 92.47185460000037 seconds\n","Processing record 117\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 97.75568460000068 seconds\n","Processing record 118\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 94.50997530000313 seconds\n","Processing record 119\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 93.79286089999732 seconds\n","Processing record 121\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 95.12638969999898 seconds\n","Processing record 122\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 98.90818280000167 seconds\n","Processing record 123\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 97.96478940000088 seconds\n","Processing record 124\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n","Processor =  detrend|{'method': 'polynomial', 'order': 1}\n","All methods already processed\n","Time elapsed = 92.40935610000088 seconds\n","Processing record 200\n","Processor =  None\n","Processor =  detrend|{'method': 'polynomial', 'order': 0}\n"]}],"source":["was_interrupted = False\n","total_time = 300 # seconds\n","\n","offset = 100 # seconds\n","discard_start_sec = discard_end_sec = 2\n","\n","methods = ['neurokit', 'pantompkins1985', 'hamilton2002', 'martinez2004', 'christov2004',\n","               'gamboa2008', 'elgendi2010', 'engzeemod2012', 'kalidas2017', 'rodrigues2020']\n","offset = 500 # seconds\n","\n","derised_anns = LIST_BEATS_1\n","list_processors = [\n","    Processor(None),\n","    Processor('detrend', method = 'polynomial', order = 0),\n","    Processor('detrend', method = 'polynomial', order = 1),\n","]\n","\n","dict_multi_analysis = {}\n","print(f'Total time = {total_time} seconds')\n","\n","time_str = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n","\n","count_processed = 0\n","try:\n","    for idx, row in df_record_lead_ann.iterrows():\n","        if row['upper_signal'] == 'MLII':\n","            signal_track = 0\n","        elif row['lower_signal'] == 'MLII':\n","            signal_track = 1\n","        else:\n","            continue\n","\n","        record_num = row['record']\n","\n","        # Start measuring time\n","        start_time = timer()\n","\n","        print(f'Processing record {record_num}')\n","\n","        # Load record\n","        record, ann = load_record(record_num)\n","        fs = int(record.fs)  # type: ignore\n","\n","        samples = int(total_time * fs)\n","        start_samples = int(offset * fs)\n","        end_samples = start_samples + samples\n","        \n","        dict_multi_analysis[record_num] = {}\n","        for processor in list_processors:\n","            processor_name = processor.processor_name\n","            print(f'Processor =  {processor_name}')\n","            methods_done = df_multi_analysis[\n","            (df_multi_analysis.record_num == record_num)\n","            & (df_multi_analysis.signal_track == signal_track)\n","            & (df_multi_analysis.start_samples == start_samples)\n","            & (df_multi_analysis.end_samples == end_samples)\n","            & (df_multi_analysis.processor == processor_name)\n","            ].method.to_list()\n","\n","            methods_missing = [method for method in methods if method not in methods_done]\n","\n","            if len(methods_missing) == 0:\n","                print('All methods already processed')\n","                continue\n","\n","            \n","            #dict_multi_analysis[record_num][processor_name] = {}\n","\n","            #df_beats, ecg, start_samples, end_samples, fs = create_df_beats(record_num, total_time, offset, LIST_BEATS_1, signal_track)\n","\n","            # ECG signal\n","            ecg = record.p_signal[:, signal_track][start_samples:end_samples]  # type: ignore\n","\n","            if processor.processor_name:\n","                ecg = apply_processors(ecg, processor)\n","\n","            ecg = pd.Series(ecg, dtype=ECG_TYPE)\n","            ecg.index += start_samples\n","            ann_beat_indexes = pd.Series(ann.sample, dtype=INDEX_TYPE)\n","            ann_beat_symbols = pd.Series(ann.symbol, dtype=ANN_TYPE)\n","\n","            # Mask for time window and derised annotations\n","            mask_derised_ann = ann_beat_symbols.isin(derised_anns)\n","\n","            # We are only interested in samples in the time window\n","            mask_time_window = (ann_beat_indexes >= start_samples) & (\n","                ann_beat_indexes < end_samples)\n","            mask_used_ann = mask_time_window & mask_derised_ann\n","\n","            # Apply mask\n","            ann_beat_indexes = ann_beat_indexes[mask_used_ann].reset_index(drop=True)\n","            ann_beat_symbols = ann_beat_symbols[mask_used_ann].reset_index(drop=True)\n","\n","            df_beats = correct_peaks(ecg, ann_beat_indexes, fs)\n","\n","            df_beats = df_beats.rename(columns={'index': 'peak_index', 'local_max': 'cor_peak_index'}).merge(\n","                pd.DataFrame({'peak_index': ann_beat_indexes, 'symbol': ann_beat_symbols}), on='peak_index', how='left', validate='one_to_one')\n","            \n","            #df_beats.cor_peak_index = df_beats.peak_index\n","\n","            # If the peak is not corrected, use the original peak index\n","            df_beats.loc[df_beats.cor_peak_index.isna(\n","            ), 'cor_peak_index'] = df_beats.peak_index\n","\n","\n","            first_used_sample = start_samples + discard_start_sec * fs\n","            last_used_sample = end_samples - discard_end_sec * fs\n","\n","            #dict_results = create_dict_results(ecg, methods,start_samples, first_used_sample, last_used_sample, fs, discard_start_sec, discard_end_sec)\n","            p = Pool(cpu_count())\n","            list_results = p.starmap(create_dict_results, [(ecg, [method], start_samples, first_used_sample, last_used_sample, fs, discard_start_sec, discard_end_sec) for method in methods_missing])\n","            dict_results = {}\n","            for result in list_results:\n","                for key, value in result.items():\n","                    dict_results[key] = value\n","\n","            # Now the operations are performed on the time window, we can discard the first and last n seconds\n","            ecg = ecg.loc[first_used_sample:last_used_sample ]\n","            df_beats = df_beats[(df_beats.peak_index >= first_used_sample) & (df_beats.peak_index <= last_used_sample)].reset_index(drop = True)\n","\n","            df_comp_methods = create_compare_df(df_beats, dict_results)\n","\n","            dict_metrics = calculate_metrics(df_comp_methods, methods_missing)\n","\n","            for method in dict_metrics.keys():\n","                dict_metrics[method]['signal_track'] = signal_track\n","                dict_metrics[method]['start_samples'] = start_samples\n","                dict_metrics[method]['end_samples'] = end_samples\n","            \n","\n","            dict_multi_analysis[record_num][processor_name] = dict_metrics\n","            count_processed += 1\n","        end_time = timer()\n","        print(f'Time elapsed = {end_time - start_time} seconds')\n","except KeyboardInterrupt:\n","    if count_processed > 0:\n","        with open(join(dataframes_directory, f'dict_multi_analysis_interrupted_{time_str}.pickle'), 'wb') as handle:\n","            pickle.dump(dict_multi_analysis, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        was_interrupted = True\n","\n","# save results as pickle\n","if not was_interrupted and count_processed > 0:\n","    with open(join(dataframes_directory, f'dict_multi_analysis_{time_str}.pickle'), 'wb') as handle:\n","            pickle.dump(dict_multi_analysis, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_xis_factor = 1\n","\n","fig = plot_results(\n","    dict_results, df_beats, ecg,\n","    [\n","        (\n","            df_code_description.symbol[~df_code_description.symbol.isin(\n","                LIST_BEATS_1)],\n","            dict(mode=\"markers\", marker=dict(size=4, color=\"black\"))\n","        ),\n","\n","        (LIST_BEATS_1, dict(mode=\"markers\", marker=dict(size=9, color=\"red\")))\n","    ],\n","\n","    x_xis_factor=1\n",")\n","\n","#Define x zoom\n","fig.update_xaxes(range=[271700,272300])\n","\n","fig.show()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ML","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"4f021b72c1f7cd3898f2a25ac030750b22d22f61570d94b028ffadc231687c12"}}},"nbformat":4,"nbformat_minor":0}
