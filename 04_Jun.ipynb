{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Wm28uIhy65WD"},"outputs":[],"source":["import sys\n","# Delete all global variables when re-running the notebook.\n","this = sys.modules[__name__] # type: ignore\n","for n in dir():\n","    if n in ['this', 'was_mounted']: continue\n","    if n[0]!='_': delattr(this, n)\n","\n","\n","try:\n","    was_mounted = was_mounted\n","except:\n","    was_mounted = False\n","\n","\n","import os\n","if  os.getenv(\"COLAB_RELEASE_TAG\"):\n","  is_running_on_colab = True\n","\n","else:\n","  is_running_on_colab = False\n","\n","if is_running_on_colab:\n","  packages_to_install = ['pandas==2.1.3','neurokit2', 'wfdb']\n","\n","  for package in packages_to_install:\n","    os.system(f'pip install {package}')\n","  from google.colab import drive, files\n","  code_directory = './gdrive/MyDrive/TCC/ectopic_beats_detection'\n","  if not was_mounted:\n","      drive.mount('/content/gdrive')\n","  was_mounted = True\n","  if not os.path.samefile(os.getcwd(),code_directory):\n","    os.chdir(code_directory)\n","\n","\n","import gc\n","import glob\n","import sys\n","from datetime import datetime\n","from multiprocessing import Pool, cpu_count\n","from os.path import join\n","from timeit import default_timer as timer\n","\n","import matplotlib.pyplot as plt\n","import neurokit2 as nk\n","import numpy as np\n","import pandas as pd\n","import plotly.graph_objects as go\n","import pyarrow as pa\n","import torch\n","import torch.nn as nn\n","from numba import njit\n","from torch import flatten\n","from torch.nn import Conv2d, Linear, LogSoftmax, MaxPool2d, Module, ReLU, LocalResponseNorm\n","from torchvision import transforms\n","#from torchshape import tensorshape\n","\n","from globals import *\n","from utils import load_df_multi_analysis, load_record, show_image\n","\n","\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 40)\n","\n","\n","\n","@njit(cache = True, nogil=True)\n","def sig_2_pic(signal,height, width,scale):\n","    samples = signal.shape[0]\n","    scale_image = (height-10)\n","    offset = 5\n","    new_image = np.ones((height, width), dtype=np.uint8)\n","\n","\n","    x_array = np.arange(0, samples, 1,dtype=np.int32)*(width)//(samples)\n","    y_array = (scale*scale_image*((signal - signal.min()) / (signal.max() - signal.min()))).astype(np.int32) + offset\n","\n","    for idx in range(x_array.shape[0] - 1):\n","        x0, y0, x1, y1 =x_array[idx], y_array[idx], x_array[idx+1], y_array[idx+1]\n","\n","        ############### Bresenham algorithm ###############\n","        dx = x1 - x0\n","        dy = y1 - y0\n","\n","        xsign = 1 if dx > 0 else -1\n","        ysign = 1 if dy > 0 else -1\n","\n","        dx = abs(dx)\n","        dy = abs(dy)\n","\n","        if dx > dy:\n","            xx, xy, yx, yy = xsign, 0, 0, ysign\n","        else:\n","            dx, dy = dy, dx\n","            xx, xy, yx, yy = 0, ysign, xsign, 0\n","\n","        D = 2*dy - dx\n","        y = 0\n","\n","        for x in range(dx + 1):\n","            xc, yc =  x0 + x*xx + y*yx, y0 + x*xy + y*yy\n","            new_image[height-1 - yc,xc] = 0\n","            if D >= 0:\n","                y += 1\n","                D -= 2*dx\n","            D += 2*dy\n","        ###################################################\n","\n","    return new_image\n","\n","\n","old_vars = dir()\n","\n","df_record_lead_ann = pd.read_parquet(join(dataframes_directory, 'df_record_lead_ann.parquet'))\n","df_lead_ann_summery =  pd.read_parquet(join(dataframes_directory, 'df_lead_ann_summery.parquet'))\n","df_ann_summery = pd.read_parquet(join(dataframes_directory, 'df_ann_summery.parquet'))\n","df_code_description = pd.read_parquet(join(dataframes_directory, 'df_code_description.parquet'))\n","\n","df_multi_analysis = load_df_multi_analysis(glob.glob(join(dataframes_directory, 'dict_multi_analysis*.pickle')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"M0O6uiLz65WK"},"outputs":[],"source":["list_record_track =  []\n","\n","for idx, row in df_record_lead_ann.iterrows():\n","    if row['upper_signal'] == 'MLII':\n","        signal_track = 0\n","    elif row['lower_signal'] == 'MLII':\n","        signal_track = 1\n","    else:\n","        continue\n","    list_record_track.append({'record': row['record'], 'track': signal_track})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sa9JuUwQ65WL"},"outputs":[],"source":["derised_anns = LIST_BEATS_2\n","discard_time = 100\n","df = pd.DataFrame({'record': pd.Series(dtype=np.uint8),\n","                   'ecg_beat_indexes': pd.Series(dtype=INDEX_TYPE),\n","                   'ecg_beat_indexes': pd.Series(dtype=ANN_TYPE)})\n","\n","dict_records_info = {}\n","for item in list_record_track:\n","    record_num = item['record']\n","    track_num = item['track']\n","\n","    record, ann = load_record(record_num)\n","\n","    ecg = record.p_signal[:, 0] #+ record.p_signal[:, 1] # type: ignore\n","\n","    ecg_beat_indexes = pd.Series(ann.sample, dtype=INDEX_TYPE)\n","    ecg_beat_anns = pd.Series(ann.symbol, dtype=ANN_TYPE)\n","\n","     # Mask for time window and derised annotations\n","    mask_derised_ann = ecg_beat_anns.isin(derised_anns)\n","\n","    ecg_beat_indexes = ecg_beat_indexes[mask_derised_ann].reset_index(drop=True)\n","    ecg_beat_anns = ecg_beat_anns[mask_derised_ann].reset_index(drop=True)\n","\n","    aux_df = pd.DataFrame(\n","    {\n","        'record': record_num * np.ones(ecg_beat_indexes.shape[0]-2, dtype=np.uint8),\n","        'ecg_beat_indexes': ecg_beat_indexes.iloc[1:-1],\n","        'ecg_beat_anns': ecg_beat_anns.iloc[1:-1]\n","    }\n","    )\n","\n","    df = pd.concat([df, aux_df], ignore_index=True, axis=0)\n","\n","    dict_records_info[record_num] = {\n","    'ecg': ecg,\n","    'ecg_beat_indexes': ecg_beat_indexes,\n","    'ecg_beat_anns': ecg_beat_anns\n","    }\n","k_folds = 10\n","\n","dict_df_beat_type = {}\n","for beat_type in derised_anns:\n","    # Shuffle the dataframe and save it in a dictionary\n","    aux_df = df[df['ecg_beat_anns'] == beat_type].sample(frac=1).reset_index(drop=True).copy()\n","\n","    aux_df['fold'] = (aux_df.index/(aux_df.shape[0] +1) * (k_folds)).astype(np.uint8)\n","\n","    dict_df_beat_type[beat_type] = {\n","        'df':aux_df,\n","        'idx': 0\n","        }\n","\n","\n","beat_type_quants = df.ecg_beat_anns.value_counts()\n","\n","for v in dir():\n","    if v not in old_vars + ['dict_df_beat_type', 'list_record_track', 'dict_records_info', 'old_vars', 'derised_anns', 'beat_type_quants', 'k_folds']:\n","        #print(v)\n","        delattr(this, v)\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1702829859600,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"DKKHPnMd65WM","outputId":"a4482f6e-13c7-44c7-88dd-87840bb68c27"},"outputs":[],"source":["\n","# Implement Alexnet architecture in Pytorch\n","\n","class AlexNet(Module):\n","    def __init__(self, num_classes=2):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n","            nn.BatchNorm2d(64),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","            Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.BatchNorm2d(192),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","            Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(384),\n","            ReLU(inplace=True),\n","            Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            ReLU(inplace=True),\n","            Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            Linear(256 * 3 * 3, 4096),\n","            ReLU(inplace=True),\n","            Linear(4096, 4096),\n","            ReLU(inplace=True),\n","            Linear(4096, num_classes),\n","            #LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","\n","dict_beat_to_int = {\n","    'N': 0,\n","    'L': 1,\n","    'R': 2,\n","    'V': 3,\n","    '/': 4,\n","    'A': 5,\n","    '!': 6,\n","    'E': 7,\n","}\n","\n","dict_beat_acronyms = {\n","    'N': 'NOR',\n","    'L': 'LBB',\n","    'R': 'RBB',\n","    'V': 'PVC',\n","    '/' : 'PAB',\n","    'A': 'APC',\n","    '!' : 'VFW',\n","    'E': 'VEB',\n","\n","}\n","\n","\n","dict_quant_per_batch = {\n","    'N': 10,\n","    'L': 5,\n","    'R': 5,\n","    'V': 5,\n","    '/': 3,\n","    'A': 2,\n","    '!': 1,\n","    'E': 1,\n"," }\n","\n","\n","quant_per_batch = sum(dict_quant_per_batch.values())\n","\n","print(f'{quant_per_batch} beats per batch')\n","\n","quant_per_batch = sum(dict_quant_per_batch.values())\n","\n","print(f'{quant_per_batch} beats per batch')\n","\n","\n","height = 128\n","width = 128\n","\n","print(f'height: {height}, width: {width}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1702829859601,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"-6PJBsuWjzda"},"outputs":[],"source":["def get_signal_from_df(df, idx, rm_left=20, rm_right=20):\n","    ecg_beat_idx = df.iloc[idx]['ecg_beat_indexes']\n","    record_num = df.iloc[idx]['record']\n","\n","    ecg_beat_indexes = dict_records_info[record_num]['ecg_beat_indexes']\n","    ecg_beat_anns = dict_records_info[record_num]['ecg_beat_anns']\n","    ecg = dict_records_info[record_num]['ecg']\n","\n","    ann_beat_index = ecg_beat_indexes[ecg_beat_indexes == ecg_beat_idx].index[0]\n","    beat_type = ecg_beat_anns[ann_beat_index]\n","\n","    middle = ecg_beat_indexes[ann_beat_index]\n","    start = ecg_beat_indexes[ann_beat_index -1]\n","    end = ecg_beat_indexes[ann_beat_index + 1]\n","\n","    return ecg[start+rm_left:end-rm_right], beat_type\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gdNwfsl_65WN","outputId":"b25030f4-b6f3-424e-fae0-5ecc896e7a4b"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","print('Creating instance of model')\n","model = AlexNet(num_classes=len(dict_beat_to_int)).to(device)\n","torch.save(model.state_dict(), './temp.pth')\n","\n","mult_batch = 1\n","x_np = np.zeros((quant_per_batch * mult_batch, height, width), dtype=np.uint8)\n","\n","\n","dict_fold_accuracies = {}\n","dict_fold_type_accuracies = {}\n","for fold in range(k_folds):\n","    print(f'Fold: {fold}')\n","\n","    dict_fold_type_accuracies[fold] = {}\n","    # 10[N beats/epoch] * 750[epochs/fold] * 10[folds] = 75000 N beats\n","    # All normal beats are used at least once\n","    np.random.seed(42)\n","    torch.manual_seed(42)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    if fold != 0:\n","        model.load_state_dict(torch.load('./temp.pth'))\n","    model.train()\n","\n","    for fold_epoch in range(800):\n","        list_beat_type =[]\n","        ############################## Start batch creation ##############################\n","        for beat_type in derised_anns:\n","            for beat_pic_idx in range(dict_quant_per_batch[beat_type] * mult_batch):\n","                df = dict_df_beat_type[beat_type]['df']\n","                df = df[df.fold != fold]\n","                shape = df.shape[0]\n","                beat_type_idx = dict_df_beat_type[beat_type]['idx']\n","                if beat_type_idx >= shape:\n","                    dict_df_beat_type[beat_type]['idx'] = beat_type_idx = 0\n","                else:\n","                    dict_df_beat_type[beat_type]['idx'] = beat_type_idx + 1\n","\n","                ecg, beat_type = get_signal_from_df(df, beat_type_idx, 20+np.random.randint(10), 20+np.random.randint(10))\n","\n","                beat_pic = sig_2_pic(\n","                    signal = ecg,\n","                    height = height,\n","                    width = width,\n","                    scale = np.random.randint(70,100)/100\n","                    )\n","                x_np[beat_pic_idx] = beat_pic\n","                beat_pic_idx += 1\n","                list_beat_type.append(dict_beat_to_int[beat_type])\n","\n","        ############################## End batch creation ##############################\n","\n","\n","\n","        #[N, C, W, H] = NumSamples x NumChannels x Width x Height\n","        x_train = torch.from_numpy(x_np.reshape(quant_per_batch * mult_batch,1, height, width)).float().to(device)\n","        y_train_labels = torch.tensor(list_beat_type, dtype=torch.long).to(device)\n","        y_train_onehot = nn.functional.one_hot(y_train_labels, num_classes=len(dict_beat_to_int)).float()\n","\n","        # Forward pass: Compute predicted y by passing x to the model\n","        y_pred = model(x_train)\n","        # Compute loss\n","        loss =  loss_fn(y_pred, y_train_onehot)\n","\n","        # Zero gradients, perform a backward pass, and update the weights.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if fold_epoch % 10 == 0:\n","            ########################################### start per fold tests ###########################################\n","            fold_accuracy = 0\n","            total_fold_tests = 0\n","            for beat_type in derised_anns:\n","                if beat_type not in dict_fold_type_accuracies[fold]:\n","                    dict_fold_type_accuracies[fold][beat_type] = []\n","\n","                df = dict_df_beat_type[beat_type]['df']\n","                df = df[df.fold == fold]\n","                shape = min(df.shape[0],1000)\n","                beat_type_idx = 0\n","                fold_type_accuracy = 0\n","\n","                ################################### start per beat type tests ###################################\n","                while(True):\n","                    list_beat_type =[]\n","                    for beat_pic_idx in range(quant_per_batch * mult_batch):\n","\n","                        ecg, beat_type = get_signal_from_df(df, beat_type_idx, 20+np.random.randint(10), 20+np.random.randint(10))\n","\n","                        beat_pic = sig_2_pic(\n","                            signal = ecg,\n","                            height = height,\n","                            width = width,\n","                            scale = np.random.randint(70,100)/100\n","                            )\n","                        x_np[beat_pic_idx] = beat_pic\n","                        list_beat_type.append(dict_beat_to_int[beat_type])\n","\n","                        beat_type_idx += 1\n","\n","                        if beat_type_idx == shape:\n","                            break\n","\n","                    x_test = torch.from_numpy(x_np[:beat_pic_idx+1].reshape(beat_pic_idx+1,1, height, width)).float().to(device)\n","                    y_train_labels = torch.tensor(list_beat_type, dtype=torch.long).to(device)\n","                    with torch.inference_mode():\n","                        y_pred = model(x_test)\n","\n","                    y_pred_labels = y_pred.argmax(dim=1)\n","\n","                    # Compute metrics\n","                    # True positive\n","                    tp = (y_pred_labels == y_train_labels).sum().item()\n","                    # False positive\n","                    fp = (y_pred_labels != y_train_labels).sum().item()\n","\n","                    # Accuracy for beat type and fold weighted by number of beats (beat_pic_idx)\n","                    fold_type_accuracy += beat_pic_idx*(100 * tp / (tp + fp))/shape\n","\n","                    if beat_type_idx == shape:\n","                        dict_fold_type_accuracies[fold][beat_type].append(fold_type_accuracy)\n","                        break\n","                ################################### end per beat type tests ###################################\n","                fold_accuracy += shape * fold_type_accuracy\n","                total_fold_tests+=shape\n","            fold_accuracy = fold_accuracy/total_fold_tests\n","            dict_fold_accuracies[fold] = fold_accuracy\n","            print(f'\\t Epoch {fold_epoch} Accuracy: {fold_accuracy:.4f}')\n","\n","            for beat_type, accuracies in dict_fold_type_accuracies[fold].items():\n","                print(f'\\t\\t{beat_type}: {np.mean([accuracies[-1]]):.4f}')\n","            ########################################### end per fold tests ###########################################\n","\n","\n","# Save results using pickle\n","import pickle\n","with open('./dict_fold_accuracies.pickle', 'wb') as handle:\n","    pickle.dump(dict_fold_accuracies, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","with open('./dict_fold_type_accuracies.pickle', 'wb') as handle:\n","    pickle.dump(dict_fold_type_accuracies, handle, protocol=pickle.HIGHEST_PROTOCOL)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
