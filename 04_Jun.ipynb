{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69982,"status":"ok","timestamp":1702811540547,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"Wm28uIhy65WD","outputId":"88afb5d8-7d27-4698-83c5-23b5514dfb74"},"outputs":[],"source":["import sys\n","# Delete all global variables when re-running the notebook.\n","this = sys.modules[__name__] # type: ignore\n","for n in dir():\n","    if n in ['this', 'was_mounted']: continue\n","    if n[0]!='_': delattr(this, n)\n","\n","\n","try:\n","    was_mounted = was_mounted\n","except:\n","    was_mounted = False\n","\n","\n","import os\n","if  os.getenv(\"COLAB_RELEASE_TAG\"):\n","  is_running_on_colab = True\n","\n","else:\n","  is_running_on_colab = False\n","\n","if is_running_on_colab:\n","  packages_to_install = ['pandas==2.1.3','neurokit2', 'wfdb']\n","\n","  for package in packages_to_install:\n","    os.system(f'pip install {package}')\n","  from google.colab import drive, files\n","  code_directory = './gdrive/MyDrive/TCC/ectopic_beats_detection'\n","  if not was_mounted:\n","      drive.mount('/content/gdrive')\n","  was_mounted = True\n","  if not os.path.samefile(os.getcwd(),code_directory):\n","    os.chdir(code_directory)\n","\n","\n","import gc\n","import glob\n","import sys\n","from datetime import datetime\n","from multiprocessing import Pool, cpu_count\n","from os.path import join\n","from timeit import default_timer as timer\n","\n","import matplotlib.pyplot as plt\n","import neurokit2 as nk\n","import numpy as np\n","import pandas as pd\n","import plotly.graph_objects as go\n","import pyarrow as pa\n","import torch\n","import torch.nn as nn\n","from numba import njit\n","from torch import flatten\n","from torch.nn import Conv2d, Linear, LogSoftmax, MaxPool2d, Module, ReLU, LocalResponseNorm\n","from torchvision import transforms\n","#from torchshape import tensorshape\n","\n","from globals import *\n","from utils import load_df_multi_analysis, load_record, show_image\n","\n","\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 40)\n","\n","\n","\n","@njit(cache = True, nogil=True)\n","def sig_2_pic(signal,height, width,scale):\n","    samples = signal.shape[0]\n","    scale_image = (height-10)\n","    offset = 5\n","    new_image = np.ones((height, width), dtype=np.uint8)\n","\n","\n","    x_array = np.arange(0, samples, 1,dtype=np.int32)*(width)//(samples)\n","    y_array = (scale*scale_image*((signal - signal.min()) / (signal.max() - signal.min()))).astype(np.int32) + offset\n","\n","    for idx in range(x_array.shape[0] - 1):\n","        x0, y0, x1, y1 =x_array[idx], y_array[idx], x_array[idx+1], y_array[idx+1]\n","\n","        ############### Bresenham algorithm ###############\n","        dx = x1 - x0\n","        dy = y1 - y0\n","\n","        xsign = 1 if dx > 0 else -1\n","        ysign = 1 if dy > 0 else -1\n","\n","        dx = abs(dx)\n","        dy = abs(dy)\n","\n","        if dx > dy:\n","            xx, xy, yx, yy = xsign, 0, 0, ysign\n","        else:\n","            dx, dy = dy, dx\n","            xx, xy, yx, yy = 0, ysign, xsign, 0\n","\n","        D = 2*dy - dx\n","        y = 0\n","\n","        for x in range(dx + 1):\n","            xc, yc =  x0 + x*xx + y*yx, y0 + x*xy + y*yy\n","            new_image[height-1 - yc,xc] = 0\n","            if D >= 0:\n","                y += 1\n","                D -= 2*dx\n","            D += 2*dy\n","        ###################################################\n","\n","    return new_image\n","\n","\n","old_vars = dir()\n","\n","df_record_lead_ann = pd.read_parquet(join(dataframes_directory, 'df_record_lead_ann.parquet'))\n","df_lead_ann_summery =  pd.read_parquet(join(dataframes_directory, 'df_lead_ann_summery.parquet'))\n","df_ann_summery = pd.read_parquet(join(dataframes_directory, 'df_ann_summery.parquet'))\n","df_code_description = pd.read_parquet(join(dataframes_directory, 'df_code_description.parquet'))\n","\n","df_multi_analysis = load_df_multi_analysis(glob.glob(join(dataframes_directory, 'dict_multi_analysis*.pickle')))"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702811545273,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"M0O6uiLz65WK"},"outputs":[],"source":["list_record_track =  []\n","\n","for idx, row in df_record_lead_ann.iterrows():\n","    if row['upper_signal'] == 'MLII':\n","        signal_track = 0\n","    elif row['lower_signal'] == 'MLII':\n","        signal_track = 1\n","    else:\n","        continue\n","    list_record_track.append({'record': row['record'], 'track': signal_track})\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33474,"status":"ok","timestamp":1702811579708,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"sa9JuUwQ65WL","outputId":"d6f124a3-2d38-446b-fad7-eb663495c0d6"},"outputs":[{"data":{"text/plain":["79195"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["derised_anns = LIST_BEATS_2\n","discard_time = 100\n","df = pd.DataFrame({'record': pd.Series(dtype=np.uint8),\n","                   'ecg_beat_indexes': pd.Series(dtype=INDEX_TYPE),\n","                   'ecg_beat_indexes': pd.Series(dtype=ANN_TYPE)})\n","\n","dict_records_info = {}\n","for item in list_record_track:\n","    record_num = item['record']\n","    track_num = item['track']\n","\n","    record, ann = load_record(record_num)\n","\n","    ecg = record.p_signal[:, 0] #+ record.p_signal[:, 1] # type: ignore\n","\n","    ecg_beat_indexes = pd.Series(ann.sample, dtype=INDEX_TYPE)\n","    ecg_beat_anns = pd.Series(ann.symbol, dtype=ANN_TYPE)\n","\n","     # Mask for time window and derised annotations\n","    mask_derised_ann = ecg_beat_anns.isin(derised_anns)\n","\n","    ecg_beat_indexes = ecg_beat_indexes[mask_derised_ann].reset_index(drop=True)\n","    ecg_beat_anns = ecg_beat_anns[mask_derised_ann].reset_index(drop=True)\n","\n","    aux_df = pd.DataFrame(\n","    {\n","        'record': record_num * np.ones(ecg_beat_indexes.shape[0]-2, dtype=np.uint8),\n","        'ecg_beat_indexes': ecg_beat_indexes.iloc[1:-1],\n","        'ecg_beat_anns': ecg_beat_anns.iloc[1:-1]\n","    }\n","    )\n","\n","    df = pd.concat([df, aux_df], ignore_index=True, axis=0)\n","\n","    dict_records_info[record_num] = {\n","    'ecg': ecg,\n","    'ecg_beat_indexes': ecg_beat_indexes,\n","    'ecg_beat_anns': ecg_beat_anns\n","    }\n","k_folds = 10\n","\n","dict_df_beat_type = {}\n","for beat_type in derised_anns:\n","    # Shuffle the dataframe and save it in a dictionary\n","    aux_df = df[df['ecg_beat_anns'] == beat_type].sample(frac=1).reset_index(drop=True).copy()\n","\n","    aux_df['fold'] = (aux_df.index/(aux_df.shape[0] +1) * (k_folds)).astype(np.uint8)\n","\n","    dict_df_beat_type[beat_type] = {\n","        'df':aux_df,\n","        'idx': 0\n","        }\n","\n","\n","beat_type_quants = df.ecg_beat_anns.value_counts()\n","\n","for v in dir():\n","    if v not in old_vars + ['dict_df_beat_type', 'list_record_track', 'dict_records_info', 'old_vars', 'derised_anns', 'beat_type_quants', 'k_folds']:\n","        #print(v)\n","        delattr(this, v)\n","gc.collect()"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2460,"status":"ok","timestamp":1702811582142,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"DKKHPnMd65WM","outputId":"14669239-0297-4fa6-9364-cbd144ba9b29"},"outputs":[{"name":"stdout","output_type":"stream","text":["32 beats per batch\n","32 beats per batch\n","height: 128, width: 128\n"]},{"ename":"RuntimeError","evalue":"Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mg:\\My Drive\\TCC\\ectopic_beats_detection\\04_Jun.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W3sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m42\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m model \u001b[39m=\u001b[39m AlexNet(num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dict_beat_to_int))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W3sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./alexnet.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W3sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W3sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1112\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[0;32m   1113\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1116\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1117\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1118\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1121\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 217\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[0;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n","\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."]}],"source":["# Implement Alexnet architecture in Pytorch\n","\n","class AlexNet(Module):\n","    def __init__(self, num_classes=2):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n","            nn.BatchNorm2d(64),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","            Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.BatchNorm2d(192),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","            Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(384),\n","            ReLU(inplace=True),\n","            Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            ReLU(inplace=True),\n","            Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            ReLU(inplace=True),\n","            MaxPool2d(kernel_size=3, stride=2),\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),\n","            Linear(256 * 3 * 3, 4096),\n","            ReLU(inplace=True),\n","            Linear(4096, 4096),\n","            ReLU(inplace=True),\n","            Linear(4096, num_classes),\n","            #LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","\n","dict_beat_to_int = {\n","    'N': 0,\n","    'L': 1,\n","    'R': 2,\n","    'V': 3,\n","    '/': 4,\n","    'A': 5,\n","    '!': 6,\n","    'E': 7,\n","}\n","\n","dict_beat_acronyms = {\n","    'N': 'NOR',\n","    'L': 'LBB',\n","    'R': 'RBB',\n","    'V': 'PVC',\n","    '/' : 'PAB',\n","    'A': 'APC',\n","    '!' : 'VFW',\n","    'E': 'VEB',\n","\n","}\n","\n","\n","dict_quant_per_batch = {\n","    'N': 10,\n","    'L': 5,\n","    'R': 5,\n","    'V': 5,\n","    '/': 3,\n","    'A': 2,\n","    '!': 1,\n","    'E': 1,\n"," }\n","\n","\n","quant_per_batch = sum(dict_quant_per_batch.values())\n","\n","print(f'{quant_per_batch} beats per batch')\n","\n","quant_per_batch = sum(dict_quant_per_batch.values())\n","\n","print(f'{quant_per_batch} beats per batch')\n","\n","\n","height = 128\n","width = 128\n","\n","print(f'height: {height}, width: {width}')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def get_signal_from_df(df, idx, rm_left=20, rm_right=20):\n","    ecg_beat_idx = df.iloc[idx]['ecg_beat_indexes']\n","    record_num = df.iloc[idx]['record']\n","\n","    ecg_beat_indexes = dict_records_info[record_num]['ecg_beat_indexes']\n","    ecg_beat_anns = dict_records_info[record_num]['ecg_beat_anns']\n","    ecg = dict_records_info[record_num]['ecg']\n","\n","    ann_beat_index = ecg_beat_indexes[ecg_beat_indexes == ecg_beat_idx].index[0]\n","    beat_type = ecg_beat_anns[ann_beat_index]\n","\n","    middle = ecg_beat_indexes[ann_beat_index]\n","    start = ecg_beat_indexes[ann_beat_index -1]\n","    end = ecg_beat_indexes[ann_beat_index + 1]\n","\n","    return ecg[start+rm_left:end-rm_right], beat_type\n"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"executionInfo":{"elapsed":1182227,"status":"error","timestamp":1702779434693,"user":{"displayName":"Vinícius Almeida","userId":"13624117960268289849"},"user_tz":180},"id":"gdNwfsl_65WN","outputId":"03f9f592-f72a-46b0-edd1-c5a403594f76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating instance of model\n","Fold: 0\n","N\n","\t Accuracy: 99.6000\n","/\n","\t Accuracy: 0.0731\n","L\n","\t Accuracy: 0.0000\n","R\n","\t Accuracy: 0.0000\n","A\n","\t Accuracy: 0.0000\n","V\n","\t Accuracy: 0.0000\n","!\n","\t Accuracy: 0.0000\n","E\n","\t Accuracy: 0.0000\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mg:\\My Drive\\TCC\\ectopic_beats_detection\\04_Jun.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m# Zero gradients, perform a backward pass, and update the weights.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mif\u001b[39;00m fold_epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/TCC/ectopic_beats_detection/04_Jun.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39m########################################### start per fold tests ###########################################\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n","File \u001b[1;32mc:\\Users\\Vinicius\\anaconda3\\envs\\ML\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","loss_fn = nn.CrossEntropyLoss()\n","\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","print('Creating instance of model')\n","model = AlexNet(num_classes=len(dict_beat_to_int)).to(device)\n","torch.save(model.state_dict(), './temp.pth')\n","\n","mult_batch = 8\n","x_np = np.zeros((quant_per_batch * mult_batch, height, width), dtype=np.uint8)\n","\n","\n","\n","\n","\n","dict_fold_accuracies = {}\n","dict_fold_type_accuracies = {}\n","for fold in range(k_folds):\n","    print(f'Fold: {fold}')\n","\n","    dict_fold_type_accuracies[fold] = {}\n","    # 10[N beats/epoch] * 750[epochs/fold] * 10[folds] = 75000 N beats\n","    # All normal beats are used at least once\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    if fold != 0:\n","        model.load_state_dict(torch.load('./temp.pth'))\n","    model.train()\n","\n","    for fold_epoch in range(800):\n","        list_beat_type =[]\n","        ############################## Start batch creation ##############################\n","        for beat_type in derised_anns:\n","            for beat_pic_idx in range(dict_quant_per_batch[beat_type] * mult_batch):\n","                df = dict_df_beat_type[beat_type]['df']\n","                df = df[df.fold != fold]\n","                shape = df.shape[0]\n","                beat_type_idx = dict_df_beat_type[beat_type]['idx']\n","                if beat_type_idx >= shape:\n","                    dict_df_beat_type[beat_type]['idx'] = beat_type_idx = 0\n","                else:\n","                    dict_df_beat_type[beat_type]['idx'] = beat_type_idx + 1\n","\n","                ecg, beat_type = get_signal_from_df(df, beat_type_idx, 20+np.random.randint(10), 20+np.random.randint(10))\n","\n","                beat_pic = sig_2_pic(\n","                    signal = ecg,\n","                    height = height,\n","                    width = width,\n","                    scale = np.random.randint(70,100)/100\n","                    )\n","                x_np[beat_pic_idx] = beat_pic\n","                beat_pic_idx += 1\n","                list_beat_type.append(dict_beat_to_int[beat_type])\n","\n","        ############################## End batch creation ##############################\n","                \n","\n","        \n","        #[N, C, W, H] = NumSamples x NumChannels x Width x Height\n","        x_train = torch.from_numpy(x_np.reshape(quant_per_batch * mult_batch,1, height, width)).float().to(device)\n","        y_train_labels = torch.tensor(list_beat_type, dtype=torch.long).to(device)\n","        y_train_onehot = nn.functional.one_hot(y_train_labels, num_classes=len(dict_beat_to_int)).float()\n","\n","        # Forward pass: Compute predicted y by passing x to the model\n","        y_pred = model(x_train)\n","        # Compute loss\n","        loss =  loss_fn(y_pred, y_train_onehot)\n","\n","        # Zero gradients, perform a backward pass, and update the weights.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if fold_epoch % 10 == 0:\n","            ########################################### start per fold tests ###########################################\n","            fold_accuracy = 0\n","            total_fold_tests = 0\n","            for beat_type in derised_anns:\n","                print(beat_type)\n","                if beat_type not in dict_fold_type_accuracies[fold]:\n","                    dict_fold_type_accuracies[fold][beat_type] = []\n","\n","                df = dict_df_beat_type[beat_type]['df']\n","                df = df[df.fold == fold]\n","                shape = min(df.shape[0],1000)\n","                beat_type_idx = 0\n","                fold_type_accuracy = 0\n","                \n","                ################################### start per beat type tests ###################################\n","                while(True):\n","                    list_beat_type =[]\n","                    for beat_pic_idx in range(quant_per_batch * mult_batch):\n","                        \n","                        ecg, beat_type = get_signal_from_df(df, beat_type_idx, 20+np.random.randint(10), 20+np.random.randint(10))\n","\n","                        beat_pic = sig_2_pic(\n","                            signal = ecg,\n","                            height = height,\n","                            width = width,\n","                            scale = np.random.randint(70,100)/100\n","                            )\n","                        x_np[beat_pic_idx] = beat_pic\n","                        list_beat_type.append(dict_beat_to_int[beat_type])\n","\n","                        beat_type_idx += 1\n","\n","                        if beat_type_idx == shape:\n","                            break\n","\n","                    x_test = torch.from_numpy(x_np[:beat_pic_idx+1].reshape(beat_pic_idx+1,1, height, width)).float().to(device)\n","                    y_train_labels = torch.tensor(list_beat_type, dtype=torch.long).to(device)\n","                    with torch.inference_mode():\n","                        y_pred = model(x_test)\n","\n","                    y_pred_labels = y_pred.argmax(dim=1)\n","\n","                    # Compute metrics\n","                    # True positive\n","                    tp = (y_pred_labels == y_train_labels).sum().item()\n","                    # False positive\n","                    fp = (y_pred_labels != y_train_labels).sum().item()\n","                    \n","                    # Accuracy for beat type and fold weighted by number of beats (beat_pic_idx)\n","                    fold_type_accuracy += beat_pic_idx*(100 * tp / (tp + fp))/shape\n","                    \n","                    if beat_type_idx == shape:\n","                            dict_fold_type_accuracies[fold][beat_type].append(fold_type_accuracy)\n","                            fold_accuracy += shape * fold_type_accuracy\n","                            total_fold_tests+=shape\n","                            break                            \n","                ################################### end per beat type tests ###################################\n","                fold_accuracy = fold_accuracy/total_fold_tests\n","                dict_fold_accuracies[fold] = fold_accuracy\n","\n","                print(f'\\t Accuracy: {fold_accuracy:.4f}')\n","            ########################################### end per fold tests ###########################################"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/plain":["{0: {'N': [99.6], '/': []}}"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["dict_fold_type_accuracies"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["beat_type_idx"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["231"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["beat_pic_idx"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["231"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["beat_pic_idx"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["232"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["1000 - 3*(8*32)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["shape"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["256.0"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["4194304 /(128*128)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" \n","                            break\n","                        \n","\n","\n","                    with torch.inference_mode():\n","                        y_pred = model(x_train)\n","\n","                    if beat_type_idx == shape:\n","                        break\n","\n","            y_pred_labels = y_pred.argmax(dim=1)\n","            # Compute metrics\n","            # True positive\n","            tp = (y_pred_labels == y_train_labels).sum().item()\n","            # False positive\n","            fp = (y_pred_labels != y_train_labels).sum().item()\n","\n","            # Accuracy\n","            accuracy += (100 * tp / (tp + fp))/75\n","    print(f'Epoch {epoch} | Fold {fold}: acc: {accuracy:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXCf2s7U65WO"},"outputs":[],"source":["with torch.inference_mode():\n","    y_pred = model(x_train)\n","    y_pred_labels = y_pred.argmax(dim=1)\n","    # Compute metrics\n","    # True positive\n","    tp = (y_pred_labels == y_train_labels).sum().item()\n","    # False positive\n","    fp = (y_pred_labels != y_train_labels).sum().item()\n","\n","    # Accuracy\n","    acc = 100 * tp / (tp + fp)\n","    print(f'Accuracy: {acc:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIBlUBS765WP"},"outputs":[],"source":["from mpl_toolkits.axes_grid1 import ImageGrid\n","\n","\n","fig = plt.figure(figsize=(20., 10.))\n","grid = ImageGrid(fig, 111,  # similar to subplot(111)\n","                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n","                 axes_pad=0.6,  # pad between axes in inch.\n","                 )\n","\n","for j in range(quant_per_batch):\n","    ax = grid[j]\n","    show_image(x_np[j], axis= ax)\n","    ax.set_title(f'{j+1} - {list_beat_type[j]}')\n","\n","plt.savefig(os.path.join(figures_directory, 'jun_2018/batch_example.png'))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
